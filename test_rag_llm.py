import os
import fitz  # PyMuPDF
import tempfile
import streamlit as st
from dotenv import load_dotenv

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_anthropic import ChatAnthropic

import pytesseract
from PIL import Image
import io

# ğŸ”§ OCR ê²½ë¡œ ì„¤ì • (Windows)
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

# ğŸ§  PDF í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ (OCR fallback í¬í•¨)
def extract_text_with_fallback(doc):
    page_texts = []
    for page in doc:
        text = page.get_text()
        if len(text.strip()) < 30 or "ï¿½" in text:
            pix = page.get_pixmap()
            img = Image.open(io.BytesIO(pix.tobytes("png")))
            text = pytesseract.image_to_string(img, lang="kor+eng")
        page_texts.append(text)
    return page_texts

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
CLAUDE_API_KEY = os.getenv("ANTHROPIC_API_KEY")

# ğŸ›ï¸ Streamlit UI ì„¤ì •
st.set_page_config(page_title="ğŸ“š PDF RAG vs LLM ë¹„êµ", page_icon="ğŸ“„")
st.title("ğŸ“˜ PDF ê¸°ë°˜ ì§ˆë¬¸ì‘ë‹µ (RAG vs LLM ë¹„êµ)")

# ğŸ“ íŒŒì¼ ì—…ë¡œë“œ + ì§ˆì˜ ì…ë ¥
uploaded_pdf = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])
question = st.text_input("â“ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

# ğŸ§¾ íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
if uploaded_pdf:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_pdf.read())
        tmp_path = tmp_file.name

    doc = fitz.open(tmp_path)
    page_texts = extract_text_with_fallback(doc)
    doc.close()

    # âœ‚ï¸ í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
    with st.spinner("ğŸ” PDF ì²­í¬ ìƒì„± ì¤‘..."):
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=700,
            chunk_overlap=100,
            separators=["\n\n", "\n", "â€¢", "â–¶", ":", "1.", "2.", "3.", "-", ". "]
        )
        all_texts = "\n".join(page_texts)
        docs = text_splitter.create_documents([all_texts])

        # âœ… ì²­í¬ ë¯¸ë¦¬ë³´ê¸°ë§Œ í‘œì‹œ
        with st.expander("ğŸ“‘ ë¶„í• ëœ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°"):
            for idx, doc in enumerate(docs):
                st.markdown(f"**ì²­í¬ {idx + 1}**\n\n{doc.page_content}")

        # ğŸ” ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-sts")
        vectorstore = FAISS.from_documents(docs, embeddings)
        retriever = vectorstore.as_retriever(search_type="mmr", search_kwargs={"k": 10})

        # ğŸ§  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = PromptTemplate.from_template("""
        ë„ˆëŠ” ì—…ë¡œë“œëœ PDF ë¬¸ì„œì— ê¸°ë°˜í•´ì„œ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µí•˜ëŠ” í•œêµ­ì–´ ì±—ë´‡ì´ì•¼.
        ì•„ë˜ ë¬¸ë§¥ì„ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µí•˜ê³ , ë¬¸ë§¥ì— ì—†ìœ¼ë©´ 'ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•´.

        [ë¬¸ë§¥]
        {context}

        [ì§ˆë¬¸]
        {question}

        [ë‹µë³€]
        """)

        # ğŸ¤– LLM í˜¸ì¶œ ì„¤ì • (Claude)
        llm = ChatAnthropic(model="claude-3-haiku-20240307", api_key=CLAUDE_API_KEY, temperature=0)

        rag_chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )

# â“ ì§ˆë¬¸ ì…ë ¥ ì‹œ ì‘ë‹µ ìƒì„±
if question and uploaded_pdf:
    with st.spinner("ğŸ¤– RAG ì‘ë‹µ ìƒì„± ì¤‘..."):
        rag_response = rag_chain.invoke(question)

    with st.spinner("ğŸ¤– LLM ë‹¨ë… ì‘ë‹µ ìƒì„± ì¤‘..."):
        direct_prompt = f"""
        ë„ˆëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë¬¸ì„œ ì—†ì´ë„ ì •í™•í•˜ê²Œ ë‹µí•˜ëŠ” í•œêµ­ì–´ ì±—ë´‡ì´ì•¼.
        ì§ˆë¬¸ì— ëŒ€í•´ ì•Œê³  ìˆëŠ” ì§€ì‹ìœ¼ë¡œ ìµœëŒ€í•œ ì„±ì‹¤í•˜ê²Œ ë‹µí•´ì¤˜.

        [ì§ˆë¬¸]
        {question}

        [ë‹µë³€]
        """
        llm_response = llm.invoke(direct_prompt)

    st.markdown("### ğŸ” RAG ê¸°ë°˜ ì‘ë‹µ")
    st.success(f"**Claude + PDF Context:**\n\n{rag_response}")

    st.markdown("### ğŸ§  LLM ë‹¨ë… ì‘ë‹µ")
    st.info(f"**Claude ë‹¨ë… ì‘ë‹µ:**\n\n{llm_response}")
