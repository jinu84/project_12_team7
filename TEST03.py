import os
import fitz  # PyMuPDF
import tempfile
import streamlit as st
from dotenv import load_dotenv

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_anthropic import ChatAnthropic

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
CLAUDE_API_KEY = os.getenv("ANTHROPIC_API_KEY")

# Streamlit UI ì„¤ì •
st.set_page_config(page_title="ğŸ“š PDF RAG ì‘ë‹µ", page_icon="ğŸ“„", layout="wide")
st.title(":blue_book: PDF ê¸°ë°˜ ì§ˆë¬¸ì‘ë‹µ (RAG ê¸°ë°˜)")

if "pdf_required" not in st.session_state:
    st.session_state.pdf_required = False

st.subheader("ğŸ“ ê¶ê¸ˆí•˜ì‹  ì œí’ˆì„ ì„ íƒí•´ì£¼ì„¸ìš”")

items = [
    ("ğŸŒ€", "ì—ì–´ì½˜"),
    ("ğŸ§Š", "ëƒ‰ì¥ê³ /uae40ì¹˜ëƒ‰ì¥ê³ "),
    ("ğŸ§º", "ì„¸íƒê¸°/ê±´ì¡°ê¸°/ì—ì–´ë“œë ˆì„œ"),
    ("ğŸ“±", "ëª¨ë°”ì¼"),
    ("ğŸ’»", "PC"),
    ("ğŸ–¨ï¸", "í”„ë¦°í„°/ë³µí•©ê¸°"),
    ("ğŸ“º", "TV"),
    ("ğŸªŸ", "ëª¨ë‹ˆí„°"),
    ("ğŸ§¹", "ì²­ì†Œê¸°"),
    ("ğŸ«§", "ê³µê¸°ì •ì •ê¸°/ì œìŠµê¸°"),
    ("ğŸ³", "ì£¼ë°©ê±´ì „"),
    ("ğŸ”Œ", "ìŠ¤ë§ˆíŠ¸í™ˆ/ê¸°íƒ€")
]

# ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown("""
<style>
    div[data-testid="column"] > div {
        display: flex;
        justify-content: center;
    }
    button[kind="secondary"] {
        height: 90px !important;
        width: 90px !important;
        border-radius: 14px !important;
        font-size: 13px !important;
        white-space: pre-line;
        margin: 2px !important;
    }
</style>
""", unsafe_allow_html=True)

rows = [items[i:i+4] for i in range(0, len(items), 4)]
for row in rows:
    cols = st.columns([1, 1, 1, 1], gap="small")
    for col, (icon, label) in zip(cols, row):
        with col:
            if st.button(f"{icon}\n{label}", use_container_width=True):
                st.session_state.pdf_required = True
                st.rerun()

if st.session_state.pdf_required:
    st.warning("ğŸ“„ ì„ íƒí•˜ì‹  ì œí’ˆ ê´€ë ¨ PDFë¥¼ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”")

    uploaded_pdf = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"])

    if uploaded_pdf:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_pdf.read())
            tmp_path = tmp_file.name

        doc = fitz.open(tmp_path)
        page_texts = [page.get_text() for page in doc]
        doc.close()#dlkfa

        with st.expander("ğŸ“ ì „ì²´ PDF í…ìŠ¤íŠ¸ (í˜ì´ì§€ë³„)"):
            for idx, text in enumerate(page_texts):
                with st.expander(f"ğŸ“„ Page {idx + 1}"):
                    st.text(text)

        with st.spinner("ğŸ” PDF..."):
            splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=400)
            docs = splitter.create_documents(["\n".join(page_texts)])

            embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-sts")
            vectorstore = FAISS.from_documents(docs, embeddings)
            retriever = vectorstore.as_retriever(search_type="mmr", search_kwargs={"k": 10})

            prompt = PromptTemplate.from_template("""
            ë„ˆëŠ” ì—…ë¡œë“œëœ PDF ë¬¸ì„œì— ê¹Œì§€í•´ì„œ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µí•´ì•¼ í•˜ëŠ” í•œêµ­ì–´ ì±…ë°© ì²«ì½”ì•¼.
            ë¬¸ë ¤ë¥¼ ë³´ê³  ì‘ë‹µí•˜ë¼. ëª©ë¡ì— ì—†ìœ¼ë©´ '\ubb38ì„œì— í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë‹µí•´.

            [ë¬¸ë ¤]\n{context}
            [ì§ˆë¬¸]\n{question}
            [ë‹µë³€]
            """)

            llm = ChatAnthropic(model="claude-3-haiku-20240307", api_key=CLAUDE_API_KEY, temperature=0)

            rag_chain = (
                {"context": retriever, "question": RunnablePassthrough()}
                | prompt
                | llm
                | StrOutputParser()
            )

        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []

        if question := st.chat_input("ğŸ’¬ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!"):
            st.session_state.chat_history.append(("user", question))
            with st.spinner("ğŸ¤– RAG ì‘ë‹µ ìƒì„± ì¤‘..."):
                rag_response = rag_chain.invoke(question)
            st.session_state.chat_history.append(("ai", rag_response))

        for role, msg in st.session_state.chat_history:
            with st.chat_message(role):
                st.markdown(msg)
