# ì¢‹ì€ ë²„ì „
import os
import re
import fitz  # PyMuPDF
import tempfile
import hashlib
import streamlit as st
from dotenv import load_dotenv

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_models import ChatOpenAI
from sentence_transformers import SentenceTransformer, util

@st.cache_resource
def get_bert_model():
    return SentenceTransformer("jhgan/ko-sbert-sts")

def get_bert_similarity(answer1, answer2):
    model = get_bert_model()
    emb1 = model.encode(answer1, convert_to_tensor=True)
    emb2 = model.encode(answer2, convert_to_tensor=True)
    similarity = util.pytorch_cos_sim(emb1, emb2).item()
    return round(similarity * 100, 2)  # í¼ì„¼íŠ¸ë¡œ ë°˜í™˜



# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ğŸ“š ì œí’ˆ ì¹´í…Œê³ ë¦¬
product_categories = {
    "ëª¨ë°”ì¼": ["ìŠ¤ë§ˆíŠ¸í°", "íœ´ëŒ€í°"],
    "TV/ì˜ìƒ.ìŒí–¥": ["í…”ë ˆë¹„ì „", "TV", "ì‚¬ìš´ë“œë°”"],
    "ê°€ì „": ["ëƒ‰ì¥ê³ ", "ì„¸íƒê¸°", "ì—ì–´ë“œë ˆì„œ", "ì²­ì†Œê¸°", "ê±´ì¡°ê¸°"],
    "PC / í”„ë¦°í„°": ["ì»´í“¨í„°", "ë…¸íŠ¸ë¶", "í”„ë¦°í„°", "ë³µí•©ê¸°"],
    "ë©”ëª¨ë¦¬ & ìŠ¤í† ë¦¬ì§€": ["ë©”ëª¨ë¦¬", "SSD", "microSD", "ìŠ¤í† ë¦¬ì§€"],
    "ë””ìŠ¤í”Œë ˆì´": ["ëª¨ë‹ˆí„°", "ë””ìŠ¤í”Œë ˆì´"],
    "ì¹´ë©”ë¼ & ìº ì½”ë”": ["ì¹´ë©”ë¼", "ìº ì½”ë”"]
}

# ğŸ”§ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def clean_newlines(text):
    lines = text.split('\n')
    cleaned = []
    for i in range(len(lines)):
        line = lines[i].strip()
        if i == len(lines) - 1:
            cleaned.append(line)
            break
        if not re.search(r"[.!?â€¦]$|ìŠµë‹ˆë‹¤$|í•©ë‹ˆë‹¤$|ë˜ë©°$|ë©ë‹ˆë‹¤$", line):
            cleaned.append(line + ' ')
        else:
            cleaned.append(line + '\n')
    return ''.join(cleaned)

def remove_unusual_unicode(text):
    return re.sub(r"[^\uAC00-\uD7A3\u1100-\u11FF\u3130-\u318F"
                  r"\u0041-\u005A\u0061-\u007A"
                  r"\u0030-\u0039"
                  r"\u0020-\u007E"
                  r"\u3000-\u303F\uFF00-\uFFEF"
                  r"\u2010-\u205E"
                  r"\n\r\t .,;:?!\"'()\-\u2013\u2014_=+/\\[\]{}<>%@&#~"
                  r"]+", "", text)

def extract_text_without_images(doc):
    cleaned_texts = []
    for page in doc:
        blocks = page.get_text("blocks")
        text_blocks = [block[4] for block in blocks if block[6] == 0]
        page_text = "\n".join(text_blocks).strip()
        page_text = remove_unusual_unicode(page_text)
        cleaned_texts.append(page_text)
    return cleaned_texts


# ğŸŒ Streamlit ì„¤ì •
st.set_page_config(page_title="ğŸ“š PDF ê¸°ë°˜ ì±—ë´‡", page_icon="ğŸ“„")
menu = st.sidebar.radio("ğŸ“‚ ë©”ë‰´ ì„ íƒ", ["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ’¬ ì±—ë´‡", "ğŸ“Š ì‘ë‹µ ë¹„êµ"])

# ğŸ”„ ê³µìœ  ë°ì´í„° ì´ˆê¸°í™”
if "uploaded_data" not in st.session_state:
    st.session_state.uploaded_data = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ğŸ“ íŒŒì¼ ì—…ë¡œë“œ í™”ë©´
if menu == "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ":
    st.title("ğŸ“ PDF ì—…ë¡œë“œ ë° ì œí’ˆ ë¶„ë¥˜")

    uploaded_pdfs = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"], accept_multiple_files=True)

    if uploaded_pdfs:
        st.session_state.uploaded_data.clear()
        for uploaded_pdf in uploaded_pdfs:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_pdf.read())
                tmp_path = tmp_file.name

            doc = fitz.open(tmp_path)
            page_texts = extract_text_without_images(doc)
            doc.close()

            full_text = "\n".join(page_texts)
            cleaned_text = clean_newlines(full_text)

            llm = ChatOpenAI(model="gpt-4o", temperature=0, openai_api_key=OPENAI_API_KEY)

            category_prompt = PromptTemplate.from_template("""
            ì•„ë˜ëŠ” ì œí’ˆ ë¶„ë¥˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤:
            {categories}

            ì•„ë˜ ë¶„ë¥˜ ë¦¬ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜ë¥¼ ë°˜ë“œì‹œ ì„ íƒí•˜ì—¬ ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ë‹¨ì–´ë‚˜ ì„¤ëª… ì—†ì´ ì •í™•íˆ ë¶„ë¥˜ ì´ë¦„ë§Œ í•œ ì¤„ë¡œ ì¶œë ¥í•˜ì„¸ìš”.


            [ë¬¸ì„œ ë‚´ìš© ìš”ì•½]
            {text}

            [ê´€ë ¨ ì œí’ˆ ë¶„ë¥˜]""")
            category_chain = (
                {"categories": lambda _: ", ".join(product_categories.keys()), "text": lambda _: cleaned_text[:1500]}
                | category_prompt
                | llm
                | StrOutputParser()
            )
            category = category_chain.invoke("dummy")

            matched_category = next((c for c in product_categories if c in category), None)

            name_prompt = PromptTemplate.from_template("""
            ì•„ë˜ ì„¤ëª…ì„œ ë‚´ìš©ì„ ë³´ê³  ì œí’ˆëª…ì„ ì •í™•íˆ í•œ ì¤„ë¡œ ì•Œë ¤ì£¼ì„¸ìš”. ì˜ˆ: ê°¤ëŸ­ì‹œ S24 ìš¸íŠ¸ë¼

            [ì„¤ëª…ì„œ ë‚´ìš©]
            {text}

            [ì œí’ˆëª…]""")
            name_chain = (
                {"text": lambda _: cleaned_text[:2000]}
                | name_prompt
                | llm
                | StrOutputParser()
            )
            name = name_chain.invoke("dummy").strip()

            if matched_category:
                st.session_state.uploaded_data.append({
                    "category": matched_category,
                    "product_name": name,
                    "text": cleaned_text
                })

        st.success("âœ… ë¬¸ì„œ ë¶„ë¥˜ ë° ì œí’ˆëª… ì¶”ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì±—ë´‡ íƒ­ìœ¼ë¡œ ì´ë™í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

# ğŸ’¬ ì±—ë´‡ í™”ë©´
elif menu == "ğŸ’¬ ì±—ë´‡":
    st.title("ğŸ’¬ PDF ê¸°ë°˜ RAG ì±—ë´‡")

    if not st.session_state.uploaded_data:
        st.warning("ğŸ“ ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì œí’ˆì„ ë“±ë¡í•´ì£¼ì„¸ìš”.")
        st.stop()

    categories = list(set(d["category"] for d in st.session_state.uploaded_data))


    st.subheader("ğŸ“¦ ì œí’ˆ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")
    icons = {
        "ëª¨ë°”ì¼": "ğŸ“±", "TV/ì˜ìƒ.ìŒí–¥": "ğŸ“º", "ê°€ì „": "ğŸ§º", "PC / í”„ë¦°í„°": "ğŸ’»",
        "ë©”ëª¨ë¦¬ & ìŠ¤í† ë¦¬ì§€": "ğŸ’¾", "ë””ìŠ¤í”Œë ˆì´": "ğŸ–¥ï¸", "ì¹´ë©”ë¼ & ìº ì½”ë”": "ğŸ“·"
    }
    cols = st.columns(4)
    for i, category in enumerate(icons.keys()):
        with cols[i % 4]:
            if category in categories:
                if st.button(f"{icons[category]} {category}", key=category):
                    st.session_state.selected_category = category
            else:
                st.button(f"{icons[category]} {category}", key=category, disabled=True)
    # ì„ íƒëœ ì¹´í…Œê³ ë¦¬ ê°’
    selected_category = st.session_state.get("selected_category", None)

    #ì œí’ˆëª…ì„ íƒ
    if selected_category:
        products = [d["product_name"] for d in st.session_state.uploaded_data if d["category"] == selected_category]
        
        if products:
            # ğŸ‘‰ ê¸°ë³¸ ì•ˆë‚´ ë¬¸êµ¬ ì¶”ê°€
            product_options = ["ì œí’ˆëª…ì„ ê³ ë¥´ì„¸ìš”"] + products
            selected_product = st.selectbox("ğŸ·ï¸ ì œí’ˆëª… ì„ íƒ", product_options)

            # ì‹¤ì œ ì œí’ˆì´ ì„ íƒëœ ê²½ìš°ì—ë§Œ ì§„í–‰
            if selected_product != "ì œí’ˆëª…ì„ ê³ ë¥´ì„¸ìš”":
                product_data = next((d for d in st.session_state.uploaded_data if d["product_name"] == selected_product), None)
                if product_data:
                    product_text = product_data["text"]
                    
                    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                    docs = splitter.create_documents([product_text])
                    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-sts")
                    vectorstore = FAISS.from_documents(docs, embeddings)
                    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 10})

                    def format_chat(chat_pairs):
                        return "\n".join([f"{'ì‚¬ìš©ì' if r == 'user' else 'ì±—ë´‡'}: {m}" for r, m in chat_pairs[:-1]])
                else:
                    st.warning("â— ì„ íƒí•œ ì œí’ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ğŸ“­ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("ğŸ“¦ ë¨¼ì € ì œí’ˆ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")


    prompt = PromptTemplate.from_template("""
    ë„ˆëŠ” ì—…ë¡œë“œëœ PDF ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” í•œêµ­ì–´ ì±—ë´‡ì´ì•¼.
    ë¬¸ì„œì— ì—†ëŠ” ì§ˆë¬¸ì´ë©´ "ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë§í•´ì¤˜.

    [ëŒ€í™” íˆìŠ¤í† ë¦¬]
    {chat_history}

    [ì§ˆë¬¸]
    {question}

    [ë¬¸ë§¥]
    {context}

    [ë‹µë³€]
    """)

    rag_chain = (
        {
            "question": lambda h: h[-1][1],
            "chat_history": lambda h: format_chat(h),
            "context": lambda h: retriever.invoke(h[-1][1])
        }
        | prompt
        | ChatOpenAI(model="gpt-4o", temperature=0, openai_api_key=OPENAI_API_KEY)
        | StrOutputParser()
    )

    if user_input := st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!"):
        st.session_state.chat_history.append(("user", user_input))
        with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
            answer = rag_chain.invoke(st.session_state.chat_history)
        st.session_state.chat_history.append(("ai", answer))

        # ğŸ”½ ì—¬ê¸°ì— ì¶”ê°€
        st.session_state.last_question = user_input
        st.session_state.last_rag_answer = answer

        base_4o_prompt = PromptTemplate.from_template("""[ì§ˆë¬¸]\n{question}\n\n[ë‹µë³€]""")
        base_4o_chain = (
            {"question": lambda _: user_input}
            | base_4o_prompt
            | ChatOpenAI(model="gpt-4o", temperature=0, openai_api_key=OPENAI_API_KEY)
            | StrOutputParser()
        )
        st.session_state.last_4o_answer = base_4o_chain.invoke("dummy")

        base_35_chain = (
            {"question": lambda _: user_input}
            | base_4o_prompt
            | ChatOpenAI(model="gpt-3.5-turbo", temperature=0, openai_api_key=OPENAI_API_KEY)
            | StrOutputParser()
        )
        st.session_state.last_35_answer = base_35_chain.invoke("dummy")

    for role, msg in st.session_state.chat_history:
        with st.chat_message(role):
            st.markdown(msg)

    if 'product_text' in locals():
        with st.expander("ğŸ“„ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°"):
            preview_chunks = splitter.split_text(product_text)
            for i, chunk in enumerate(preview_chunks):
                st.markdown(f"**Chunk {i+1}**")
                st.code(chunk)


elif menu == "ğŸ“Š ì‘ë‹µ ë¹„êµ":
    st.title("ğŸ“Š RAG vs GPT-4o vs GPT-3.5 ì‘ë‹µ ë¹„êµ")

    if not all(k in st.session_state for k in ["last_question", "last_rag_answer", "last_4o_answer", "last_35_answer"]):
        st.info("ğŸ’¬ ì±—ë´‡ì—ì„œ ë¨¼ì € ì§ˆë¬¸í•˜ê³  ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.")
        st.stop()

    st.subheader("â“ ì§ˆë¬¸")
    st.markdown(f"> {st.session_state.last_question}")

    st.subheader("ğŸ§  RAG ê¸°ë°˜ ì‘ë‹µ")
    st.markdown(st.session_state.last_rag_answer)

    st.subheader("ğŸ§  GPT-4o (RAG ì—†ì´)")
    st.markdown(st.session_state.last_4o_answer)

    st.subheader("ğŸ§  GPT-3.5 (RAG ì—†ì´)")
    st.markdown(st.session_state.last_35_answer)

    st.divider()

    st.subheader("ğŸ“ BERT ê¸°ë°˜ ìœ ì‚¬ë„ (%)")
    col1, col2, col3 = st.columns(3)

    with col1:
        score_4o = get_bert_similarity(st.session_state.last_rag_answer, st.session_state.last_4o_answer)
        st.metric("RAG vs GPT-4o", f"{score_4o}%")
    with col2:
        score_35 = get_bert_similarity(st.session_state.last_rag_answer, st.session_state.last_35_answer)
        st.metric("RAG vs GPT-3.5", f"{score_35}%")
    with col3:
        score_4o_35 = get_bert_similarity(st.session_state.last_4o_answer, st.session_state.last_35_answer)
        st.metric("GPT-4o vs GPT-3.5", f"{score_4o_35}%")


