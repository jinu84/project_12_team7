import os
import re
import fitz  # PyMuPDF
import tempfile
import hashlib
import streamlit as st
from dotenv import load_dotenv

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_models import ChatOpenAI


# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ğŸ“š ì œí’ˆ ì¹´í…Œê³ ë¦¬
product_categories = {
    "ëª¨ë°”ì¼": ["ìŠ¤ë§ˆíŠ¸í°", "íœ´ëŒ€í°"],
    "TV/ì˜ìƒ.ìŒí–¥": ["í…”ë ˆë¹„ì „", "TV", "ì‚¬ìš´ë“œë°”"],
    "ê°€ì „": ["ëƒ‰ì¥ê³ ", "ì„¸íƒê¸°", "ì—ì–´ë“œë ˆì„œ", "ì²­ì†Œê¸°", "ê±´ì¡°ê¸°"],
    "PC / í”„ë¦°í„°": ["ì»´í“¨í„°", "ë…¸íŠ¸ë¶", "í”„ë¦°í„°", "ë³µí•©ê¸°"],
    "ë©”ëª¨ë¦¬ & ìŠ¤í† ë¦¬ì§€": ["ë©”ëª¨ë¦¬", "SSD", "microSD", "ìŠ¤í† ë¦¬ì§€"],
    "ë””ìŠ¤í”Œë ˆì´": ["ëª¨ë‹ˆí„°", "ë””ìŠ¤í”Œë ˆì´"],
    "ì¹´ë©”ë¼ & ìº ì½”ë”": ["ì¹´ë©”ë¼", "ìº ì½”ë”"]
}

# ğŸ”§ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜
def clean_newlines(text):
    lines = text.split('\n')
    cleaned = []
    for i in range(len(lines)):
        line = lines[i].strip()
        if i == len(lines) - 1:
            cleaned.append(line)
            break
        if not re.search(r"[.!?â€¦]$|ìŠµë‹ˆë‹¤$|í•©ë‹ˆë‹¤$|ë˜ë©°$|ë©ë‹ˆë‹¤$", line):
            cleaned.append(line + ' ')
        else:
            cleaned.append(line + '\n')
    return ''.join(cleaned)

def remove_unusual_unicode(text):
    return re.sub(r"[^\uAC00-\uD7A3\u1100-\u11FF\u3130-\u318F"
                  r"\u0041-\u005A\u0061-\u007A"
                  r"\u0030-\u0039"
                  r"\u0020-\u007E"
                  r"\u3000-\u303F\uFF00-\uFFEF"
                  r"\u2010-\u205E"
                  r"\n\r\t .,;:?!\"'()\-\u2013\u2014_=+/\\[\]{}<>%@&#~"
                  r"]+", "", text)

def extract_text_without_images(doc):
    cleaned_texts = []
    for page in doc:
        blocks = page.get_text("blocks")
        text_blocks = [block[4] for block in blocks if block[6] == 0]
        page_text = "\n".join(text_blocks).strip()
        page_text = remove_unusual_unicode(page_text)
        cleaned_texts.append(page_text)
    return cleaned_texts


# ğŸŒ Streamlit ì„¤ì •
st.set_page_config(page_title="ğŸ“š PDF ê¸°ë°˜ ì±—ë´‡", page_icon="ğŸ“„")
menu = st.sidebar.radio("ğŸ“‚ ë©”ë‰´ ì„ íƒ", ["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ’¬ ì±—ë´‡"])

# ğŸ”„ ê³µìœ  ë°ì´í„° ì´ˆê¸°í™”
if "uploaded_data" not in st.session_state:
    st.session_state.uploaded_data = []
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ğŸ“ íŒŒì¼ ì—…ë¡œë“œ í™”ë©´
if menu == "ğŸ“ íŒŒì¼ ì—…ë¡œë“œ":
    st.title("ğŸ“ PDF ì—…ë¡œë“œ ë° ì œí’ˆ ë¶„ë¥˜")

    uploaded_pdfs = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["pdf"], accept_multiple_files=True)

    if uploaded_pdfs:
        st.session_state.uploaded_data.clear()
        for uploaded_pdf in uploaded_pdfs:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_pdf.read())
                tmp_path = tmp_file.name

            doc = fitz.open(tmp_path)
            page_texts = extract_text_without_images(doc)
            doc.close()

            full_text = "\n".join(page_texts)
            cleaned_text = clean_newlines(full_text)

            llm = ChatOpenAI(model="gpt-4o", temperature=0, openai_api_key=OPENAI_API_KEY)

            category_prompt = PromptTemplate.from_template("""
            ì•„ë˜ëŠ” ì œí’ˆ ë¶„ë¥˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤:
            {categories}

            ìœ„ ë¶„ë¥˜ ì¤‘ ì—…ë¡œë“œëœ ë¬¸ì„œ ë‚´ìš©ì— ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì œí’ˆ ë¶„ë¥˜ í•˜ë‚˜ë§Œ ê³¨ë¼ì£¼ì„¸ìš”.

            [ë¬¸ì„œ ë‚´ìš© ìš”ì•½]
            {text}

            [ê´€ë ¨ ì œí’ˆ ë¶„ë¥˜]""")
            category_chain = (
                {"categories": lambda _: ", ".join(product_categories.keys()), "text": lambda _: cleaned_text[:1500]}
                | category_prompt
                | llm
                | StrOutputParser()
            )
            category = category_chain.invoke("dummy")

            matched_category = next((c for c in product_categories if c in category), None)

            name_prompt = PromptTemplate.from_template("""
            ì•„ë˜ ì„¤ëª…ì„œ ë‚´ìš©ì„ ë³´ê³  ì œí’ˆëª…ì„ ì •í™•íˆ í•œ ì¤„ë¡œ ì•Œë ¤ì£¼ì„¸ìš”. ì˜ˆ: ê°¤ëŸ­ì‹œ S24 ìš¸íŠ¸ë¼

            [ì„¤ëª…ì„œ ë‚´ìš©]
            {text}

            [ì œí’ˆëª…]""")
            name_chain = (
                {"text": lambda _: cleaned_text[:2000]}
                | name_prompt
                | llm
                | StrOutputParser()
            )
            name = name_chain.invoke("dummy").strip()

            if matched_category:
                st.session_state.uploaded_data.append({
                    "category": matched_category,
                    "product_name": name,
                    "text": cleaned_text
                })

        st.success("âœ… ë¬¸ì„œ ë¶„ë¥˜ ë° ì œí’ˆëª… ì¶”ì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì±—ë´‡ íƒ­ìœ¼ë¡œ ì´ë™í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

# ğŸ’¬ ì±—ë´‡ í™”ë©´
elif menu == "ğŸ’¬ ì±—ë´‡":
    st.title("ğŸ’¬ PDF ê¸°ë°˜ RAG ì±—ë´‡")

    if not st.session_state.uploaded_data:
        st.warning("ğŸ“ ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì œí’ˆì„ ë“±ë¡í•´ì£¼ì„¸ìš”.")
        st.stop()

    categories = list(set(d["category"] for d in st.session_state.uploaded_data))
    selected_category = st.selectbox("ğŸ“¦ ì¹´í…Œê³ ë¦¬ ì„ íƒ", categories)

    products = [d["product_name"] for d in st.session_state.uploaded_data if d["category"] == selected_category]
    selected_product = st.selectbox("ğŸ·ï¸ ì œí’ˆëª… ì„ íƒ", products)

    product_data = next((d for d in st.session_state.uploaded_data if d["product_name"] == selected_product), None)
    product_text = product_data["text"]

    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    docs = splitter.create_documents([product_text])
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sbert-sts")
    vectorstore = FAISS.from_documents(docs, embeddings)
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 10})

    def format_chat(chat_pairs):
        return "\n".join([f"{'ì‚¬ìš©ì' if r == 'user' else 'ì±—ë´‡'}: {m}" for r, m in chat_pairs[:-1]])

    prompt = PromptTemplate.from_template("""
    ë„ˆëŠ” ì—…ë¡œë“œëœ PDF ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” í•œêµ­ì–´ ì±—ë´‡ì´ì•¼.
    ë¬¸ì„œì— ì—†ëŠ” ì§ˆë¬¸ì´ë©´ "ë¬¸ì„œì— í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë§í•´ì¤˜.

    [ëŒ€í™” íˆìŠ¤í† ë¦¬]
    {chat_history}

    [ì§ˆë¬¸]
    {question}

    [ë¬¸ë§¥]
    {context}

    [ë‹µë³€]
    """)

    rag_chain = (
        {
            "question": lambda h: h[-1][1],
            "chat_history": lambda h: format_chat(h),
            "context": lambda h: retriever.invoke(h[-1][1])
        }
        | prompt
        | ChatOpenAI(model="gpt-4o", temperature=0, openai_api_key=OPENAI_API_KEY)
        | StrOutputParser()
    )

    if user_input := st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!"):
        st.session_state.chat_history.append(("user", user_input))
        with st.spinner("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘..."):
            answer = rag_chain.invoke(st.session_state.chat_history)
        st.session_state.chat_history.append(("ai", answer))

    for role, msg in st.session_state.chat_history:
        with st.chat_message(role):
            st.markdown(msg)

    with st.expander("ğŸ“„ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°"):
        for i, chunk in enumerate(splitter.split_text(product_text)):
            st.markdown(f"**Chunk {i+1}**")
            st.code(chunk)
